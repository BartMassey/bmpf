\documentclass[12pt]{article}
\usepackage{bigpage}
\usepackage{blockpar}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}

\newcommand{\asgn}{\,\,\leftarrow\,\,}
\newcommand{\newcode}{\\*[0.5\baselineskip]}
\newcommand{\Prob}{\textrm{Pr}}

\title{Linear Time Weighted Resampling}
\author{Bart Massey}
\date{17 August 2007}

\begin{document}
  \maketitle

  \begin{abstract}
  We describe an optimal algorithm for perfect weighted resampling
  of a population, with time complexity $O(m + n)$ for
  resampling $m$ inputs to produce $n$ outputs.  This
  is a substantial performance improvement over
  typically-used resampling algorithms, and a quality
  improvement over the
  approximate linear-time algorithm that represent the
  state of the art.  Our resampling algorithm is also easily
  parallelizable, with linear speedup.
  Linear-time resampling yields
  substantial improvements in our motivating example of
  Bayesian Particle Filtering.
  \end{abstract}

\section{Introduction}

  Bayesian Particle Filtering (BPF)~\cite{?} is an exciting new methodology
  for state space tracking and sensor fusion.  The bottleneck
  step in BPF is weighted resampling: creating a new
  population of ``particles'' from an old population by
  random sampling from the source population according to
  the particle weights.    Consider resampling $m$ inputs to
  produce $n$ outputs.  A standard na\"ive algorithm has time complexity
  $O(mn)$. Algorithms with complexity $O(m + n \log m)$ are easy
  to find, although they seem not to be widely used in
  practice.  Instead, typical BPF implementations will resample
  using the expensive $O(mn)$ algorithm, but only
  sporadically.  A more recent approach is to use a linear
  time algorithm, but one that produces a sample that is
  only approximately correctly weighted~\cite{?}.

  We introduce an algorithm with time complexity $O(m + n)$
  (requiring just the normal $O(m + n)$ space) that produces
  a perfectly weighted sample. For a simple array
  representation of the output, simply initializing the
  output will require time $O(n)$.  It seems that the input
  must be scanned at least once just to determine the total
  input weight for normalization.  Thus, our algorithm is
  apparently optimal.

  BPF is typically computation-limited, and all of the other
  steps in a BPF iteration require time linear in the
  population size.  By linearizing resampling, we remove the
  resampling bottleneck, allowing much higher population
  sizes that in turn dramatically improve BPF performance.

  A good starting point for describing our algorithm is to
  review some resampling algorithms.  We describe our
  algorithm and report its effectiveness in a BPF
  implementation.

\section{Weighted Resampling Algorithms}

  There are a number of approaches to the weighted
  resampling problem.  In this section, we describe some
  weighted resampling algorithms in order of increasing time
  efficiency.  We conclude with the description of our
  $O(m + n)$ algorithm.

  For what follows, assume an array $s$ of $m$ input
  samples, and an output array $s'$ that will hold the $n$
  output samples of the resampling.  Assume further that
  associated with each sample $s_i$ is a weight $w(s_i)$,
  and that the weights have been normalized to sum to 1.
  This can of course be done in time $O(m)$, but typical
  efficient implementations keep a running weight total
  during weight generation, and then normalize their
  sampling range rather than normalizing the weights
  themselves.  We thus discount the normalization cost in
  our analysis.

\subsection{A Na\"ive $O(mn)$ Resampling Algorithm}\label{sec-naive}

  The na\"ive approach to resampling has been re-invented
  many times.  A correct, if inefficient, way to resample is
  via the pseudocode of Figure~\ref{fig-omn}.  The {\em
  sample} procedure selects the first sample such that the
  sum of weights in the input up to and including this
  sample is greater than some index value $\mu$.  The index
  value is chosen in {\em resample} by uniform random
  sampling from the distribution $[0..1]$, with each output
  position being filled in turn.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it sample}$(\mu)$: \\
      \>$t \asgn 0$ \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $m$ {\bf do} \\
      \>\>$t \asgn t + w(s_i)$ \\
      \>\>{\bf if} $t > \mu$ {\bf then} \\
      \>\>\>{\bf return} $s_i$ \newcode
      {\bf to} {\it resample}: \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $n$ {\bf do} \\
      \>\>$\mu \asgn \textit{random-real}([0..1])$ \\
      \>\>$s'_i \asgn sample(\mu)$
      \end{tabbing}
    \end{minipage}
    \caption{Na\"ive Resampling}\label{fig-omn}
  \end{figure}

  The na\"ive algorithm has its advantages.  It is easy to
  verify that it is a perfect sampling algorithm.  It is
  easy to implement, and easy to parallelize.  The expected
  running time is $o(\frac{1}{2}mn)$.  If the distribution
  of weights is uneven enough, the proportionality constant
  might be improved by paying $O(m \log m)$ time up front to
  sort the input array so that the largest weights occur
  first (but this does not seem to work well in practice).
  Irregardless, resampling is still the bottleneck step in a
  typical BPF implementation.

\subsection{A Heap-based $O(m + n \log m)$ Resampling Algorithm}\label{sec-heap}

  One simple way to improve the performance of the na\"ive
  algorithm is to improve upon the linear scan performed by
  {\em sample} in Figure~\ref{fig-omn}.

  For example, imagine that the input array is treated as a
  binary heap.  In time $O(m)$ we can compute and cache the
  sum $w_l$ of weights of the left sub-heap of each position
  in the input, as shown in Figure~\ref{fig-heap}.  First,
  the sum at each heap position is computed bottom-up and
  stored as $w_t$.  This then gives $w_l$ as simply the
  $w_t$ of the left child.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it init-weights}: \\
      \>{\bf for} $i$ {\bf from} $m$ {\bf downto} $1$ {\bf do} \\
      \>\>{\bf if} $2i > m$ {\bf then} \\
      \>\>\>$w_t(s_i) \asgn w(s_i)$ \\
      \>\>{\bf else if} $2i + 1 > m$ {\bf then} \\
      \>\>\>$w_t(s_i) \asgn w_t(s_{2i}) + w(s_i)$ \\
      \>\>{\bf else}\\
      \>\>\>$w_t(s_i) \asgn w_t(s_{2i}) + w(s_i) + w_t(s_{2i+1})$ \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $m$ {\bf do} \\
      \>\>{\bf if} $2i > m$ {\bf then} \\
      \>\>\>$w_l(s_i) \asgn 0$ \\
      \>\>{\bf else} \\
      \>\>\>$w_l(s_i) \asgn w_t(s_{2i})$
    \end{tabbing}
    \end{minipage}
    \caption{Computing Weights of Left Sub-heaps}\label{fig-heap}
  \end{figure}

  Given $w_l$, {\em sample} can perform a scan for the
  correct input weight in time $O(\log m)$ by scanning down
  from the top of the heap, as shown in
  Figure~\ref{fig-onlm}.  At each step, if the target
  variate $\mu$ is less than the weight of the left subtree,
  the scan descends left.  If $\mu$ is greater than the
  weight of the left subtree by less than the weight of the
  current node the scan terminates and this node is
  selected.  Otherwise, the scan descends right.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it sample}$(\mu,i)$: \\
      \>{\bf if} $\mu \le w_l(s_i)$ {\bf then} \\
      \>\>{\bf return} {\it sample}$(\mu,2i)$ \\
      \>{\bf if} $\mu \le w_l(s_i) + w(s_i)$ {\bf then} \\
      \>\>{\bf return} $s_i$ \\
      \>{\bf return} {\it sample}$(\mu,2i + 1)$
    \end{tabbing}
    \end{minipage}
    \caption{Heap-based Sampling}\label{fig-onlm}
  \end{figure}

  This algorithm is a bit more complex than the na\"ive one,
  but it dramatically improves upon the worst-case running
  time.  As with the na\"ive algorithm, constant-factor
  improvements might be possible by actually heapifying the input
  such that the largest-weighted inputs are near the top.
  Heapification is also $O(m)$ time and can be done in
  place, so there is no computational complexity penalty for
  this optimization.  However, it is an extra step, and the
  constant factors may not be worth it.

  For the normal case of resampling, we would like to get
  rid of the $\log m$ penalty per output sample.  However,
  there is a rarely-occuring special case in which this
  algorithm is quite efficient.  Consider an offline
  sampling problem in which we plan to repeatedly draw a
  small number of samples from the same extremely large
  input distribution.  Because the input distribution
  remains fixed, the cost of heapification can be amortized
  away, yielding an amortized $O(n \log m)$ algorithm.

\subsection{A Merge-based $O(m + n \log n)$ Resampling Algorithm}\label{sec-merge}

  One can imagine trying to improve upon the complexity of
  the heap-style algorithm by using some more efficient data
  structure.  However, there is a fundamental tradeoff---the
  setup for an improved algorithm needs to continue to have
  a cost low in $m$.  Otherwise, any savings in resampling
  will be swamped by setup in the common case that $m
  \approx n$.

  A better plan is to try to improve the na\"ive algorithm
  in a different way.  The real problem with the na\"ive
  algorithm is not so much the cost per scan as it is the
  fact that each scan is independent.  It seems a shame not
  to reuse the work of the initial scan in subsequent scans.

  Let us generate an array $u$ of $n$ variates up-front,
  then sort it.  At this point, a {\em merge} operation, as
  shown in Figure~\ref{fig-merge}, can be used to generate
  all $n$ outputs in a single pass over the $m$ inputs.  The
  merge operation is simple.  Walk the input array once.
  Each time the sum of weights hits the current variate
  $u_i$, output a sample and move to the next variate
  $u_{i+1}$.  The time complexity of the initial sort is
  $O(n \log n)$ and of the merge pass is $O(m + n)$, for a
  total time complexity of $O(m + n \log n)$.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it merge}$(u)$: \\
      \>$j \asgn 1$ \\
      \>$t \asgn u_1$ \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $n$ {\bf do} \\
      \>\>$\mu \asgn u_i$ \\
      \>\>{\bf while} $\mu < t$ {\bf do} \\
      \>\>\>$t \asgn t + w(s_j)$ \\
      \>\>\>$j \asgn j + 1$ \\
      \>\>$s'_i \asgn s_j$
    \end{tabbing}
    \end{minipage}
    \caption{Merge-based Resampling}\label{fig-merge}
  \end{figure}

  Complexity-wise, we seem to have simply moved the $\log$
  factor of the previous algorithm from $m$ to $n$,
  replacing our $O(m + n \log m)$ algorithm with an $O(m + n
  \log n)$ one.  However, our new algorithm has an important
  distinction.  The log factor this time comes merely from
  sorting an array of uniform variates.  If we could somehow
  generate the variates in sorted order (at amortized
  constant cost) we could make this approach run in time
  $O(m + n)$.  The next section shows how to achieve this.

\subsection{An Optimal $O(m + n)$ Resampling Algorithm}\label{sec-optimal}

  As discussed in the previous section, if we can generate
  the variates comprising a uniform sample of $n$ values in
  increasing order, we can resample in time $O(m + n)$.  In
  this section, we show the simple math that achieves this
  goal.

  Assume without loss of generality that our goal is simply
  to generate the first variate in a uniform sample of $n +
  1$ values.  Call the first variate $\mu_0$, the set of
  remaining variates $U$ and note that $|U|=n$.  Now, for
  any given variate $\mu_i \in X$, we have that
    $$ \Prob(\mu_0 < \mu_i) = 1 - \mu_0 $$
  Since this is independently true for each $\mu_i$, we define
    $$p(\mu_0) = \Prob(\forall \mu_i \in U ~.~ \mu_0 < \mu_i) = (1 - \mu_0)^n$$
  
  To see how to take a weighted random sample from this
  distribution, first consider a discrete approximation that
  divides the range $0..1$ into $T$ intervals.  Given a
  random variate $\mu$, we will use $\mu_0=i_0/T$ when
  the sum of the weights of the intervals up to interval $i_0$
  is just greater than $\mu$.  Of course, the weights must be
  normalized by dividing by the total weight.  Thus we have
    $$i_0=\min_{i\in1..T}\left[{\frac{\sum_{j=1}^{i}{p(j/T)}}
                         {\sum_{j=1}^{T}{p(j/T)}} \ge \mu}\right]$$
  Figure~\ref{fig-calculus} illustrates the calculation
  here.

  \begin{figure}
    \centering
    \includegraphics{bars.eps}
    \caption{Discrete Sampling Approximation}\label{fig-calculus}
  \end{figure}

  In the limit as $T\rightarrow\infty$ our discrete
  approximation converges to an integral.  We have
    \begin{eqnarray*}
      \mu &=& \frac{\int_{u=0}^{\mu_0}{(1-u)^n \textit{du}}}
                   {\int_{u=0}^{1}{(1-u)^n \textit{du}}} \\
	  &=& \frac{\left.\frac{-(1-u)^{n+1}}{n+1}\right|_{u=0}^{\mu_0}}
		   {\left.\frac{-(1-u)^{n+1}}{n+1}\right|_{u=0}^{1}} \\
          &=& \frac{\frac{-1}{n+1}\left[(1-\mu_0)^{n+1}-1\right]}
		   {0-\frac{-1}{n+1}} \\
          &=& 1 - (1 - \mu_0)^{n+1}
    \end{eqnarray*}
  However, what we need is $\mu_0$ in terms of
  $\mu$, so we solve
    \begin{eqnarray*}
       \mu &=& 1 - (1 - \mu_0)^{n+1} \\
       (1 - \mu_0)^{n+1} &=& 1 - \mu \\
       \mu_0 &=& 1 - (1 - \mu)^\frac{1}{n+1} \\
       \mu_0 &=& 1 - \mu^\frac{1}{n+1}
    \end{eqnarray*}
  (The last step is permissible because $\mu$ is a
  uniform deviate in the range $0..1$, and therefore
  statistically equivalent to $(1-\mu)$.)

  We now have the formula we need for selecting the first
  deviate from a set of $n$ in increasing order.  To select
  the next deviate, we simply decrease $n$ by $1$, select a
  deviate from the whole range, and then scale and offset it
  to the remaining range.  We repeat this process until
  $n=0$.  (Recall that $|U|=n$, so the last deviate will be
  selected when $n=0$.)  Figure~\ref{fig-deviate} shows
  this process.
  
  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it randomize}: \\
      \>$u_1 \asgn (1-\mu)^{\frac{1}{n}}$ \\
      \>{\bf for} $i$ {\bf from} $2$ {\bf to} $n$ {\bf do} \\
      \>\>$u_i \asgn u_{i-1} + (1-u_{i-1})(1-\mu)^{\frac{1}{n-i+1}}$
    \end{tabbing}
    \end{minipage}
    \caption{Generating Deviates In Increasing Order}\label{fig-deviate}
  \end{figure}

  We now have the array $u$ of deviates in sorted order that
  we need to feed the {\em merge} algorithm of the previous
  section.  We thus have an $O(m + n)$ algorithm for random
  weighted selection.

\section{Performance}

  We implemented the na\"ive and optimal algorithms in a BPS
  tracker for simulated vehicle navigation.  The
  simulated vehicle has a GPS-like and an IMU-like device
  for navigational purposes; both the device and the vehicle
  model are noisy.  Figures~\ref{fig-track-naive} and
  \ref{fig-track-optimal} show actual and estimated vehicle
  tracks from the simulator for the 100-particle case.  Note
  that the quality of tracking of the two algorithms is
  indistinguishable, as expected.

  \begin{figure}
    \centering
    \includegraphics{track-naive-100.eps}
    \caption{Vehicle Tracking---BPF With Na\"ive Resampling}\label{fig-track-naive}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics{track-optimal-100.eps}
    \caption{Vehicle Tracking---BPF With Optimal Resampling}\label{fig-track-optimal}
  \end{figure}

\section{Discussion}

  Our optimal algorithm will parallelize reasonably well
  with some additional work. We need to derive the general
  direct expression for placing sample $k$ of $n$ for
  arbitrary $k$.
  \begin{enumerate}
  \item A master processor uses the general expression
    we have derived to break up the array of variants
    to be calculated by our $P$-processor
    machine into $P$ regions.
  \item Each processor indepedently fills in its section
    of variates in the manner described in Section~\ref{sec-optimal}.
  \item Each processor fills in a section of total accumulated
    weights in the input array as described in
    Section~\ref{sec-merge}.
  \item In a separate pass, each processor adds the sum of
    weights to its left to its section of the total accumulated
    weights in the input array.
  \item Each processor does a search for the start and end
    of its section of the heap.  This can be done in time
    $O(\log m)$ using binary search
  \item Finally, each processor samples its section of heap
    using the {\em merge} algorithm of Section~\ref{sec-merge}.
  \end{enumerate}
  
  An interesting open question is whether at reasonable
  sample sizes there is any significant difference between
  accurate weighted random sampling, and the simpler
  strategy of shuffling the input samples and then selecting
  uniformly from the weighted inputs using the {\em merge}
  approach of Section~\ref{sec-merge}.  The latter approach
  has the advantage that one avoids computing $n$ rational
  exponentiations during variate generation, which may
  significantly improve the constant factor at the expense
  of accuracy.  The Central Limit Theorem strongly suggests
  that the two approaches are largely equivalent.

\section*{Acknowledgments}

  Thanks much to Jules Kongslie, Mark Jones, Dave Archer,
  Jamey Sharp and Bryant York for conversations that led up
  to this work.  Thanks also to Jules Kongslie and to James
  McNames and his students for teaching me BPF.  It is my
  $n^{\textrm{th}}$ approach, but this time it worked.

\end{document}
