\documentclass[12pt]{article}
\usepackage{bigpage}
\usepackage{blockpar}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{url}

\newcommand{\asgn}{\,\,\leftarrow\,\,}
\newcommand{\newcode}{\\*[0.5\baselineskip]}
\newcommand{\Prob}{\text{Pr}}
\newcommand{\hyperg}{{{{}_2}{F_1}}}
\newcommand{\du}{{\text{d}u}}

\title{Linear Time Weighted Resampling}
\author{Bart Massey\\
  Assoc. Prof. Computer Science\\
  Portland State University\\
  \url{bart@cs.pdx.edu}}
\date{Draft of 24 August 2007\\{\em Do Not Distribute}}

\begin{document}
  \maketitle

  \begin{abstract}
  We describe an optimal algorithm for perfect weighted
  resampling of a population, with time complexity $O(m +
  n)$ for resampling $m$ inputs to produce $n$ outputs.
  This is a substantial performance improvement over
  typically-used resampling algorithms, and a quality
  improvement over the approximate linear-time algorithm
  that represent the state of the art.  Our resampling
  algorithm is also easily parallelizable, with linear
  speedup.  Linear-time resampling yields substantial
  improvements in our motivating example of Bayesian
  Particle Filtering.
  \end{abstract}

\section{Introduction}

  Bayesian Particle Filtering (BPF)~\cite{bpf} is an exciting
  new methodology for state space tracking and sensor
  fusion.  The bottleneck step in BPF is weighted
  resampling: creating a new population of ``particles''
  from an old population by random sampling from the source
  population according to the particle weights.  Consider
  resampling $m$ inputs to produce $n$ outputs.  A standard
  na\"ive algorithm has time complexity $O(mn)$. Algorithms
  with complexity $O(m + n \log m)$ are easy to find,
  although they seem not to be widely used in practice.
  Instead, typical BPF implementations will resample using
  the expensive $O(mn)$ algorithm, but only sporadically.  A
  more promising approach is to use a linear time algorithm,
  but one that produces a sample that is only approximately
  correctly weighted~\cite{recount}.

  We introduce an algorithm with time complexity $O(m + n)$
  (requiring just the normal $O(m + n)$ space) that produces
  a perfectly weighted sample. For a simple array
  representation of the output, simply initializing the
  output will require time $O(n)$.  It seems that the input
  must be scanned at least once just to determine the total
  input weight for normalization.  Thus, our algorithm is
  apparently optimal.

  BPF is typically computation-limited, and all of the other
  steps in a BPF iteration require time linear in the
  population size.  By linearizing resampling, we remove the
  resampling bottleneck, allowing much higher population
  sizes that in turn dramatically improve BPF performance.

  A good starting point for describing our algorithm is to
  review some resampling algorithms.  We describe our
  algorithm and report its effectiveness in a BPF
  implementation.  We conclude with a discussion of
  remaining issues.

\section{Weighted Resampling Algorithms}

  There are a number of approaches to the weighted
  resampling problem.  In this section, we describe some
  weighted resampling algorithms in order of increasing time
  efficiency.  We conclude with the description of our
  $O(m + n)$ algorithm.

  For what follows, assume an array $s$ of $m$ input
  samples, and an output array $s'$ that will hold the $n$
  output samples of the resampling.  Assume further that
  associated with each sample $s_i$ is a weight $w(s_i)$,
  and that the weights have been normalized to sum to 1.
  This can of course be done in time $O(m)$, but typical
  efficient implementations keep a running weight total
  during weight generation, and then normalize their
  sampling range rather than normalizing the weights
  themselves.  We thus discount the normalization cost in
  our analysis.

\subsection{A Na\"ive $O(mn)$ Resampling Algorithm}\label{sec-naive}

  The na\"ive approach to resampling has been re-invented
  many times.  A correct, if inefficient, way to resample is
  via the pseudocode of Figure~\ref{fig-omn}.  The {\em
  sample} procedure selects the first sample such that the
  sum of weights in the input up to and including this
  sample is greater than some index value $\mu$.  The index
  value is chosen in {\em resample} by uniform random
  sampling from the distribution $[0..1]$, with each output
  position being filled in turn.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it sample}$(\mu)$: \\
      \>$t \asgn 0$ \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $m$ {\bf do} \\
      \>\>$t \asgn t + w(s_i)$ \\
      \>\>{\bf if} $t > \mu$ {\bf then} \\
      \>\>\>{\bf return} $s_i$ \newcode
      {\bf to} {\it resample}: \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $n$ {\bf do} \\
      \>\>$\mu \asgn \textit{random-real}([0..1])$ \\
      \>\>$s'_i \asgn sample(\mu)$
      \end{tabbing}
    \end{minipage}
    \caption{Na\"ive Resampling}\label{fig-omn}
  \end{figure}

  The na\"ive algorithm has its advantages.  It is easy to
  verify that it is a perfect sampling algorithm.  It is
  easy to implement, and easy to parallelize.  The expected
  running time is $o(\frac{1}{2}mn)$.  If the distribution
  of weights is uneven enough, the proportionality constant
  might be improved by paying $O(m \log m)$ time up front to
  sort the input array so that the largest weights occur
  first (but this does not seem to work well in practice).
  Irregardless, resampling is still the bottleneck step in a
  typical BPF implementation.

\subsection{A Heap-based $O(m + n \log m)$ Resampling Algorithm}\label{sec-heap}

  One simple way to improve the performance of the na\"ive
  algorithm is to improve upon the linear scan performed by
  {\em sample} in Figure~\ref{fig-omn}.

  For example, imagine that the input array is treated as a
  binary heap.  In time $O(m)$ we can compute and cache the
  sum $w_l$ of weights of the left sub-heap of each position
  in the input, as shown in Figure~\ref{fig-heap}.  First,
  the sum at each heap position is computed bottom-up and
  stored as $w_t$.  This then gives $w_l$ as simply the
  $w_t$ of the left child.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it init-weights}: \\
      \>{\bf for} $i$ {\bf from} $m$ {\bf downto} $1$ {\bf do} \\
      \>\>{\bf if} $2i > m$ {\bf then} \\
      \>\>\>$w_t(s_i) \asgn w(s_i)$ \\
      \>\>{\bf else if} $2i + 1 > m$ {\bf then} \\
      \>\>\>$w_t(s_i) \asgn w_t(s_{2i}) + w(s_i)$ \\
      \>\>{\bf else}\\
      \>\>\>$w_t(s_i) \asgn w_t(s_{2i}) + w(s_i) + w_t(s_{2i+1})$ \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $m$ {\bf do} \\
      \>\>{\bf if} $2i > m$ {\bf then} \\
      \>\>\>$w_l(s_i) \asgn 0$ \\
      \>\>{\bf else} \\
      \>\>\>$w_l(s_i) \asgn w_t(s_{2i})$
    \end{tabbing}
    \end{minipage}
    \caption{Computing Weights of Left Sub-heaps}\label{fig-heap}
  \end{figure}

  Given $w_l$, {\em sample} can perform a scan for the
  correct input weight in time $O(\log m)$ by scanning down
  from the top of the heap, as shown in
  Figure~\ref{fig-onlm}.  At each step, if the target
  variate $\mu$ is less than the weight of the left subtree,
  the scan descends left.  If $\mu$ is greater than the
  weight of the left subtree by less than the weight of the
  current node the scan terminates and this node is
  selected.  Otherwise, the scan descends right.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it sample}$(\mu,i)$: \\
      \>{\bf if} $\mu \le w_l(s_i)$ {\bf then} \\
      \>\>{\bf return} {\it sample}$(\mu,2i)$ \\
      \>{\bf if} $\mu \le w_l(s_i) + w(s_i)$ {\bf then} \\
      \>\>{\bf return} $s_i$ \\
      \>{\bf return} {\it sample}$(\mu,2i + 1)$
    \end{tabbing}
    \end{minipage}
    \caption{Heap-based Sampling}\label{fig-onlm}
  \end{figure}

  This algorithm is a bit more complex than the na\"ive one,
  but it dramatically improves upon the worst-case running
  time.  As with the na\"ive algorithm, constant-factor
  improvements might be possible by actually heapifying the input
  such that the largest-weighted inputs are near the top.
  Heapification is also $O(m)$ time and can be done in
  place, so there is no computational complexity penalty for
  this optimization.  However, it is an extra step, and the
  constant factors may not be worth it.

  For the normal case of resampling, we would like to get
  rid of the $\log m$ penalty per output sample.  However,
  there is a rarely-occuring special case in which this
  algorithm is quite efficient.  Consider an offline
  sampling problem in which we plan to repeatedly draw a
  small number of samples from the same extremely large
  input distribution.  Because the input distribution
  remains fixed, the cost of heapification can be amortized
  away, yielding an amortized $O(n \log m)$ algorithm.

\subsection{A Merge-based $O(m + n \log n)$ Resampling Algorithm}\label{sec-merge}

  One can imagine trying to improve upon the complexity of
  the heap-style algorithm by using some more efficient data
  structure.  However, there is a fundamental tradeoff---the
  setup for an improved algorithm needs to continue to have
  a cost low in $m$.  Otherwise, any savings in resampling
  will be swamped by setup in the common case that $m
  \approx n$.

  A better plan is to try to improve the na\"ive algorithm
  in a different way.  The real problem with the na\"ive
  algorithm is not so much the cost per scan as it is the
  fact that each scan is independent.  It seems a shame not
  to reuse the work of the initial scan in subsequent scans.

  Let us generate an array $u$ of $n$ variates up-front,
  then sort it.  At this point, a {\em merge} operation, as
  shown in Figure~\ref{fig-merge}, can be used to generate
  all $n$ outputs in a single pass over the $m$ inputs.  The
  merge operation is simple.  Walk the input array once.
  Each time the sum of weights hits the current variate
  $u_i$, output a sample and move to the next variate
  $u_{i+1}$.  The time complexity of the initial sort is
  $O(n \log n)$ and of the merge pass is $O(m + n)$, for a
  total time complexity of $O(m + n \log n)$.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it merge}$(u)$: \\
      \>$j \asgn 1$ \\
      \>$t \asgn u_1$ \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $n$ {\bf do} \\
      \>\>$\mu \asgn u_i$ \\
      \>\>{\bf while} $\mu < t$ {\bf do} \\
      \>\>\>$t \asgn t + w(s_j)$ \\
      \>\>\>$j \asgn j + 1$ \\
      \>\>$s'_i \asgn s_j$
    \end{tabbing}
    \end{minipage}
    \caption{Merge-based Resampling}\label{fig-merge}
  \end{figure}

  Complexity-wise, we seem to have simply moved the $\log$
  factor of the previous algorithm from $m$ to $n$,
  replacing our $O(m + n \log m)$ algorithm with an $O(m + n
  \log n)$ one.  However, our new algorithm has an important
  distinction.  The log factor this time comes merely from
  sorting an array of uniform variates.  If we could somehow
  generate the variates in sorted order (at amortized
  constant cost) we could make this approach run in time
  $O(m + n)$.  The next section shows how to achieve this.

  Alternatively, if we could sort the variates in $O(n)$
  time, we could get an $O(m + n)$ merge-based algorithm.
  Given that what we are sorting is $n$ variates uniformly
  distributed between $0$ and $1$, a radix sort should do
  the trick here.  We are currently experimenting with this
  approach; however, the constant factors in the running
  time are expected to be poor for large $n$, since the
  radix sort has extremely poor cache behavior.  In
  Section~\ref{sec-segment} we suggest a hybrid of the radix
  sort approach and a variant of the approach of the
  next section that is expected to largely
  solve that problem.

\subsection{An Optimal $O(m + n)$ Resampling Algorithm}\label{sec-optimal}

  As discussed in the previous section, if we can generate
  the variates comprising a uniform sample of $n$ values in
  increasing order, we can resample in time $O(m + n)$.  In
  this section, we show the simple math that achieves this
  goal.

  Assume without loss of generality that our goal is simply
  to generate the first variate in a uniform sample of $n +
  1$ values.  Call the first variate $\mu_0$, the set of
  remaining variates $U$ and note that $|U|=n$.  Now, for
  any given variate $\mu_i \in X$, we have that
    $$ \Prob(\mu_0 < \mu_i) = 1 - \mu_0 $$
  Since this is independently true for each $\mu_i$, we define
    $$p(\mu_0) = \Prob(\forall \mu_i \in U ~.~ \mu_0 < \mu_i) = (1 - \mu_0)^n$$
  
  To see how to take a weighted random sample from this
  distribution, first consider a discrete approximation that
  divides the range $0..1$ into $T$ intervals.  Given a
  random variate $\mu$, we will use $\mu_0=i_0/T$ when
  the sum of the weights of the intervals up to interval $i_0$
  is just greater than $\mu$.  Of course, the weights must be
  normalized by dividing by the total weight.  Thus we have
    $$i_0=\min_{i\in1..T}\left[{\frac{\sum_{j=1}^{i}{p(j/T)}}
                         {\sum_{j=1}^{T}{p(j/T)}} \ge \mu}\right]$$
  Figure~\ref{fig-calculus} illustrates the calculation
  here.

  \begin{figure}
    \centering
    \includegraphics{bars.eps}
    \caption{Discrete Sampling Approximation}\label{fig-calculus}
  \end{figure}

  In the limit as $T\rightarrow\infty$ our discrete
  approximation converges to an integral.  We have
    \begin{eqnarray*}
      \mu &=& \frac{\int_{u=0}^{\mu_0}{(1-u)^n \du}}
                   {\int_{u=0}^{1}{(1-u)^n \du}} \\
	  &=& \frac{\left.\frac{-(1-u)^{n+1}}{n+1}\right|_{u=0}^{\mu_0}}
		   {\left.\frac{-(1-u)^{n+1}}{n+1}\right|_{u=0}^{1}} \\
          &=& \frac{\frac{-1}{n+1}\left[(1-\mu_0)^{n+1}-1\right]}
		   {0-\frac{-1}{n+1}} \\
          &=& 1 - (1 - \mu_0)^{n+1}
    \end{eqnarray*}
  However, what we need is $\mu_0$ in terms of
  $\mu$, so we solve
    \begin{eqnarray*}
       \mu &=& 1 - (1 - \mu_0)^{n+1} \\
       (1 - \mu_0)^{n+1} &=& 1 - \mu \\
       \mu_0 &=& 1 - (1 - \mu)^\frac{1}{n+1} \\
       \mu_0 &=& 1 - \mu^\frac{1}{n+1}
    \end{eqnarray*}
  (The last step is permissible because $\mu$ is a
  uniform deviate in the range $0..1$, and therefore
  statistically equivalent to $(1-\mu)$.)

  We now have the formula we need for selecting the first
  deviate from a set of $n$ in increasing order.  To select
  the next deviate, we simply decrease $n$ by $1$, select a
  deviate from the whole range, and then scale and offset it
  to the remaining range.  We repeat this process until
  $n=0$.  (Recall that $|U|=n$, so the last deviate will be
  selected when $n=0$.)  Figure~\ref{fig-deviate} shows
  this process.
  
  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it randomize}: \\
      \>$u_1 \asgn (1-\mu)^{\frac{1}{n}}$ \\
      \>{\bf for} $i$ {\bf from} $2$ {\bf to} $n$ {\bf do} \\
      \>\>$u_i \asgn u_{i-1} + (1-u_{i-1})(1-\mu)^{\frac{1}{n-i+1}}$
    \end{tabbing}
    \end{minipage}
    \caption{Generating Deviates In Increasing Order}\label{fig-deviate}
  \end{figure}

  We now have the array $u$ of deviates in sorted order that
  we need to feed the {\em merge} algorithm of the previous
  section.  We thus have an $O(m + n)$ algorithm for random
  weighted selection.

\section{Performance}

  We implemented the na\"ive and optimal algorithms in a BPS
  tracker for simulated vehicle navigation.  The
  simulated vehicle has a GPS-like and an IMU-like device
  for navigational purposes; both the device and the vehicle
  model are noisy.  Figures~\ref{fig-track-naive} and
  \ref{fig-track-optimal} show actual and estimated vehicle
  tracks from the simulator for the 100-particle case.  Note
  that the quality of tracking of the two algorithms is
  indistinguishable, as expected.

  \begin{figure}
    \centering
    \includegraphics{track-naive-100.eps}
    \caption{Vehicle Tracking---BPF With Na\"ive Resampling}\label{fig-track-naive}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics{track-optimal-100.eps}
    \caption{Vehicle Tracking---BPF With Optimal Resampling}\label{fig-track-optimal}
  \end{figure}

  The important distinction between these algorithms is not
  quality, but rather runtime.
  Figures~\ref{fig-times}-\ref{fig-timeszoom2} show the time
  in seconds for 1000 iterations of BPF with various
  resampling algorithms as a function of the number of
  particles tracked / resampled.  The benchmark machine is
  an otherwise unloaded Intel Core II Duo box at 2.13 GHz
  with 2GB of memory.  As expected, BPF using the na\"ive
  algorithm becomes unusable at larger particle sizes,
  whereas BPF using the optimal algorithm scales linearly.

  \begin{figure}
    \centering
    \includegraphics{times.eps}
    \caption{Runtimes for BPF Implementation}\label{fig-times}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics{timeszoom.eps}
    \caption{Detail of Figure~\ref{fig-times}}\label{fig-timeszoom}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics{timeszoom2.eps}
    \caption{Detail of Figure~\ref{fig-timeszoom}}\label{fig-timeszoom2}
  \end{figure}

\section{Discussion}

We have shown an $O(m + n)$ algorithm for perfect
resampling, and an extremely fast BPF implementation based
on this algorithm.  However, further speedups are possible.
In this section, we discuss some of them.

\subsection{Constant Factors}

  In a typical noise model, there is one call
  to a Gaussian-distributed pseudo-random number generator
  and to the {\tt exp()} function per particle {\em per
  sensor}: this is how the weights are updated.  This is the
  current constant-factor bottleneck in the BPF implementation.

  The cost of generating Gaussian pseudo-random numbers can
  be reduced to insignificance by using Marsaglia and
  Tsang's ``Ziggurat Method'' PRNG~\cite{ziggurat}.  We
  observed an approximate doubling of speed in our BPF
  implementation by switching to this PRNG, and it is now
  far from being the bottleneck.

  The {\tt exp()} bottleneck is harder.  One can always use
  approximate functions, or change noise distributions
  altogether.  Work is still underway in this area.

  The remaining bottleneck in resampling itself is the cost
  of the $O(n)$ calls to the {\tt pow()} function, each with
  a slightly different argument.  These rational
  exponentiations are computed during variate generation by
  calling the standard math library function {\tt pow(x,y)}.
  Since there is only one call to {\tt pow()} per particle,
  but many calls to {\tt exp()} per particle, this is not
  the bottleneck step for BPF.  However, it would be nice to
  cut it down, and approaches are available.

\subsubsection{Direct Generation of Variates}

  One way around the {\tt pow()} bottleneck is to generate
  random variates with distribution $(1 - x)^{n + 1}$ by
  some less expensive method than that of
  Section~\ref{sec-optimal}.  The Ziggurat method mentioned
  previously would be about right, except that the desired
  distribution is a two-argument function.  The most direct
  approach would lead to generating $n$ sets of Ziggurat
  tables, which would be prohibitively memory expensive for
  large $n$.

  We suspect that there is a generic rejection method for
  variate generation that will work fine for large $n$. In
  this regime, our probability expression becomes
  self-similar, and we can very accurately approximate $$
    (1 - x)^{an} \approx \left(1 - \frac{x}{a}\right)^n
  $$
  If this approximation is sufficiently accurate for some
  purpose, it could be used directly to eliminate most
  of the {\tt pow()} calls by building a Ziggurat PRNG for
  $(1-x)^{n_0}$ for some reasonably large $n_0$---probably
  around 30 or more.  The Ziggurat generator should by its
  nature replace almost all of the {\tt pow()} calls with
  simple table multiplies and compares.

  Alternatively, one could build error bounds for the
  approximation, and use these with a rejection method
  generator that also would very occasionally call {\tt
  pow()} in a corner case.

\subsubsection{Segmentation}\label{sec-segment}

  The concentration so far has been on generating the
  uniform variates sequentially.  However, there are at
  least two situations in which one would first like to
  break up the variates into blocks which are treated
  separately.

  The first such situation is to combine direct generation
  with the radix sorting approach discussed at the end of
  Section~\ref{sec-merge}.  Imagine we could generate
  ``breakpoints'' between blocks of $k$ variates for some
  small $k$, say 100, in constant time.  We could then
  generate $k$ variates uniformly and radix sort them in
  time $O(k)$.  Because the blocks would be small, the radix
  sort should hit the L0 cache and be fast, yet we would
  divid the number of {\tt pow()} calls by $k$ over the
  direct approach of Section~\ref{sec-optimal}.

  The second reason to break the variates up into blocks is
  for parallelization.  This is discussed further in
  Section~\ref{sec-parallel}.

  To break the variates up into blocks, we could try to
  derive a direct expression for placing sample $k$ of $n$
  for arbitrary $k$.  This would allow us to ``skip forward''
  by $k$ samples and place a variate, then deal with the
  intervening variates at our leisure.

  We observe that if a uniform variate $\mu_k$ is at
  position $k$ of $n$, $k - 1$ of the samples must have landed to the
  left of $\mu_k$ and $n - k$ of the samples must have
  landed to the right.  There are in general $\tbinom{n}{k-1}$
  ways this can happen, so the probability of $\mu_k$ being
  the $k^{\text{th}}$ sample is $$
    p(\mu_k) = \text{Pr}(\mu_k\text{ is at position }k) =
         \tbinom{n}{k - 1}(\mu_k)^{k-1}(1-\mu_k)^{n - k}
  $$
  The direct method used in Section~\ref{sec-optimal}
  next requires computing the probability that a variate
  $\mu$ is in the right position via $$
    p(\mu) = \text{Pr}(\mu_k = \mu) =
      \frac{\int_{u=0}^{\mu_k}{\tbinom{n}{k - 1}(\mu_k)^k(1-\mu_k)^{n - k}}\du}
           {\int_{u=0}^{1}{\tbinom{n}{k - 1}(\mu_k)^k(1-\mu_k)^{n - k}}\du}
  $$
  The integral in the denominator can be calculated
  directly. $$
    \int_{u=0}^{1}{\tbinom{n}{k - 1}(\mu_k)^k(1-\mu_k)^{n - k}}\du = 
        \tbinom{n}{k - 1}\frac{\Gamma(1 + n - k)\Gamma(k)}{\Gamma(n + 1)}
  $$
  Unfortunately, the integral in the numerator is more of a
  mess: $$
    \int_{u=0}^{\mu_k}{\tbinom{n}{k - 1}(\mu_k)^k(1-\mu_k)^{n - k}}\du =
        \tbinom{n}{k - 1}(\mu_k)^k\,\hyperg(k, -n + k; k + 1; \mu_k)
  $$
  where $\hyperg$ is Gauss's hypergeometric function.

  Any further progress in this direction appears to be
  limited by the difficulty of solving $p(\mu)$
  for $\mu_0$.  A rejection method for direction generation
  of $\mu_0$ would probably be a better approach here---a
  somewhat inefficient method would be fine, since few calls
  would be made to this generator.
  
\subsection{Paralellization}\label{sec-parallel}

  Our optimal algorithm will parallelize reasonably well
  with some additional work. 
  \begin{enumerate}
  \item Each processor fills in a section of total
    accumulated weights in the input particle array as
    described in Section~\ref{sec-merge}.
  \item In a separate pass, each processor adds the sum of
    weights computed by the processor to its left to its
    section of the total accumulated weights in the input
    particle array.
  \item A master processor uses one of the methods of
    ``skipping ahead'' in the variate
    sequence described in Section~\ref{sec-segment} to break up the
    array of variates to be calculated by our $P$-processor
    machine into $P$ regions.
  \item Each processor indepedently fills in its section
    of variates in the manner described in Section~\ref{sec-optimal}.
  \item Each processor does a search for the start and end
    of its section of the input particle array---the section
    whose total weights contain its variates.  This can be done in time
    $O(\log m)$ using binary search, with an impressively
    small constant factor.
  \item Finally, each processor samples its section of the array
    using the {\em merge} algorithm of Section~\ref{sec-merge}.
  \end{enumerate}
  

\section*{Acknowledgments}

  Thanks much to Jules Kongslie, Mark Jones, Dave Archer,
  Jamey Sharp, Josh Triplett and Bryant York for
  illuminating conversations during the discussion of this
  work.  Thanks also to Jules Kongslie and to James McNames
  and his students for teaching me BPF.  It is my
  $n^{\text{th}}$ attempt to learn the topic, but this
  time it worked.

\section*{Availability}

  Our C implementation of BPF with linear resampling
  described here is freely available under the GPL at
  \url{http://wiki.cs.pdx.edu/bartforge/bmpf}.

\bibliographystyle{plain}
\bibliography{ltrs}

\end{document}
