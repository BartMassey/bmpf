\documentclass[12pt]{article}
\usepackage{bigpage}
\usepackage{blockpar}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{url}

\newcommand{\asgn}{\,\,\leftarrow\,\,}
\newcommand{\newcode}{\\*[0.5\baselineskip]}
\newcommand{\Prob}{\text{Pr}}
\newcommand{\hyperg}{{{{}_2}{F_1}}}
\newcommand{\du}{{\text{d}u}}

\title{Linear Time Weighted Random Resampling}
\author{Bart Massey\\
  Assoc. Prof. Computer Science\\
  Portland State University\\
  \url{bart@cs.pdx.edu}}
\date{Draft of \today\\{\em Do Not Distribute}}

\begin{document}
  \maketitle

  \begin{abstract}
  We describe an algorithm for perfect weighted-random
  resampling of a population with time complexity $O(m +
  n)$ for resampling $m$ inputs to produce $n$ outputs.
  We also describe a potential constant-factor performance improvement to a
  standard algorithm with time complexity
  $O(n + n \log m)$ which is highly suitable for fixed-point
  microcontroller implementations, and a potential quality
  improvement for an $O(m+n)$ approximate algorithm with
  good constants.

  These algorithms represent minor improvements over
  standard resampling algorithms.  Our perfect resampling
  algorithm is also parallelizable, with linear speedup.
  Linear-time resampling yields notable performance
  improvements in our motivating example of Bayesian
  Particle Filtering.
  \end{abstract}

\section{Introduction}

  Bayesian Particle Filtering (BPF)~\cite{bpf} is an exciting
  new methodology for state space tracking and sensor fusion.
  The bottleneck step in BPF is weighted resampling: creating
  a new population of ``particles'' from an old population by
  random sampling from the source population according to the
  particle weights.  Consider resampling $m$ inputs to produce
  $n$ outputs.  A standard na\"ive algorithm has time
  complexity $O(mn)$.  BPF implementations that resample using
  this expensive $O(mn)$ algorithm can afford to resample only
  sporadically; this represents a difficult engineering
  tradeoff between BPF quality and computational cost.

  In this paper we first present an algorithm with
  complexity $O(m + n \log m)$ based on a binary
  heap-structured tree which is straightforward, has good
  performance, and requires no special math.  This is
  essentially a binary search method, often used in faster
  BPF implementations~\cite{arulampalam02tutorial}.  However, we introduce a potential
  performance optimization that takes advantage of the heap
  property.

  We then introduce a family of perfect and approximate
  algorithms based on the idea of simulating the scans of
  the na\"ive algorithm in parallel; making a single pass
  through the $m$ input samples and selecting $n$ output
  samples during this pass.  We introduce a novel algorithm
  with time complexity $O(m + n)$ (requiring just the normal
  $O(m + n)$ space) that produces a perfectly weighted
  sample; from this, we derive standard approximate $O(m +
  n)$ algorithms for regular resampling and
  approximate linear-time resampling.  For a simple array representation of the
  output, simply initializing the output will require time
  $O(n)$.  It seems that the input must be scanned at least
  once just to determine the total input weight for
  normalization.  Thus, the running time of our algorithms
  is apparently optimal.

  An $O(n)$ algorithm by Beadle and Djuric~\cite{recount}
  produces an output sample that is only approximately
  correctly weighted.  The basic method is to repeatedly
  randomly select an input sample, and then replicate it in
  the output sample the number of times that it would be
  expected to appear based on its fraction of the total
  weight.  As noted above, calculating the total weight
  requires $O(m)$ time, so the advantage of the $O(n)$
  algorithm over an $O(m + n)$ one is essentially lost in
  practice.  The quality of the approximation is shown to be
  reasonably good, and it is shown to work well in one BPF
  application.  However, it is only an approximate method,
  and one might expect that there are limits to the
  approximation quality.  The authors report a speedup of
  approximately 20 for 500 particles, but no other details
  are given about running time.  We suspect that the
  situation is more complicated; to investigate further
  would require independently implementing and timing this
  approach.

  BPF is typically computation-limited, and all of the other
  steps in a BPF iteration require time linear in the
  population size.  By linearizing resampling, we remove the
  resampling bottleneck, allowing higher population
  sizes that in turn dramatically improve BPF performance.

  In the remainder of this paper we review existing
  algorithms, describe our algorithms, and report the
  effectiveness of algorithms in a BPF implementation.  We
  conclude with a discussion of various issues.

\section{Weighted Resampling Algorithms}

  There are a number of approaches to the weighted
  resampling problem.  In this section, we describe some
  weighted resampling algorithms in order of increasing time
  efficiency.  We conclude with the description of some
  $O(m + n)$ algorithms.

  For what follows, assume an array $s$ of $m$ input
  samples, and an output array $s'$ that will hold the $n$
  output samples of the resampling.  Assume further that
  associated with each sample $s_i$ is a weight $w(s_i)$,
  and that the weights have been normalized to sum to 1.
  This can of course be done in time $O(m)$, but typical
  efficient implementations keep a running weight total
  during weight generation, and then normalize their
  sampling range rather than normalizing the weights
  themselves.  We thus discount the normalization cost in
  our analysis.

\subsection{A Na\"ive $O(mn)$ Resampling Algorithm}\label{sec-naive}

  The na\"ive approach to resampling has been re-invented
  many times.  A correct, if inefficient, way to resample is
  via the pseudocode of Figure~\ref{fig-omn}.  The {\em
  sample} procedure selects the first sample such that the
  sum of weights in the input up to and including this
  sample is greater than some index value $\mu$.  The index
  value is chosen in {\em resample} by uniform random
  sampling from the distribution $[0..1]$, with each output
  position being filled in turn.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it sample}$(\mu)$: \\
      \>$t \asgn 0$ \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $m$ {\bf do} \\
      \>\>$t \asgn t + w(s_i)$ \\
      \>\>{\bf if} $t > \mu$ {\bf then} \\
      \>\>\>{\bf return} $s_i$ \newcode
      {\bf to} {\it resample}: \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $n$ {\bf do} \\
      \>\>$\mu \asgn \textit{random-real}([0..1])$ \\
      \>\>$s'_i \asgn sample(\mu)$
      \end{tabbing}
    \end{minipage}
    \caption{Na\"ive Resampling}\label{fig-omn}
  \end{figure}

  The na\"ive algorithm has its advantages.  It is easy to
  verify that it is a perfect sampling algorithm.  It is
  easy to implement, and easy to parallelize.  The expected
  running time is $o(\frac{1}{2}mn)$.  If the distribution
  of weights is uneven enough, as is typical with BPF, the
  proportionality constant can be improved by paying $O(m
  \log m)$ time up front to sort the input array so that the
  largest weights occur first.  Regardless, na\"ive
  resampling is still the bottleneck step in BPF
  implementations that employ it.

\subsection{A Heap-based $O(m + n \log m)$ Resampling Algorithm}\label{sec-heap}

  One simple way to improve the performance of the na\"ive
  algorithm is to improve upon the linear scan performed by
  {\em sample} in Figure~\ref{fig-omn}.

  One way to do this is to treat the input sample array as a
  binary heap.  In time $O(m)$ we can compute and cache the
  sum $w_l$ of weights of the subtree at each position in
  the input, as shown in Figure~\ref{fig-heap}.  The sum at
  each heap position is computed bottom-up and stored as
  $w_t$.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it init-weights}: \\
      \>{\bf for} $i$ {\bf from} $m$ {\bf downto} $1$ {\bf do} \\
      \>\>$l \asgn 2i$ \\
      \>\>$r \asgn 2i + 1$ \\
      \>\>{\bf if} $l > m$ {\bf then} \\
      \>\>\>$w_t(s_i) \asgn w(s_i)$ \\
      \>\>{\bf else if} $r > m$ {\bf then} \\
      \>\>\>$w_t(s_i) \asgn w_t(s_l) + w(s_i)$ \\
      \>\>{\bf else}\\
      \>\>\>$w_t(s_i) \asgn w_t(s_l) + w(s_i) + w_t(s_r)$
    \end{tabbing}
    \end{minipage}
    \caption{Computing Weights of Sub-heaps}\label{fig-heap}
  \end{figure}

  Given $w_t$, {\em sample} can perform a scan for the
  correct input weight in time $O(\log m)$ by scanning down
  from the top of the heap, as shown in
  Figure~\ref{fig-onlm}.  At each step, if the target
  variate $\mu$ is less than the weight of the left subtree,
  the scan descends left.  If $\mu$ is greater than the
  weight of the left subtree by less than the weight of the
  current node the scan terminates and this node is
  selected.  Otherwise, the scan descends right, with
  $\mu$ adjusted downward by the cumulate weight.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it sample}$(\mu,i)$: \\
      \>$l \asgn 2i$ \\
      \>$r \asgn 2i + 1$ \\
      \>{\bf if} $\mu < w_t(s_l)$ {\bf then} \\
      \>\>{\bf return} {\it sample}$(\mu, l)$ \\
      \>{\bf if} $\mu \le w_t(s_l) + w(s_i)$ {\bf then} \\
      \>\>{\bf return} $s_i$ \\
      \>{\bf return} {\it sample}$(\mu - w_t(s_l) - w(s_i), r)$
    \end{tabbing}
    \end{minipage}
    \caption{Heap-based Sampling}\label{fig-onlm}
  \end{figure}

  This algorithm is a bit more complex than the na\"ive one,
  but it dramatically improves upon the worst-case running
  time.

  As with the na\"ive algorithm, a small constant-factor
  improvement is possible by actually heapifying the input
  such that the largest-weighted inputs are near the top.
  Heapification is also $O(m)$ time and can be done in
  place, so there is no computational complexity penalty for
  this optimization.  However, the constant factors must be
  carefully balanced; our experiments show a small net loss
  in some situations and net gain in others.  The
  controlling factor here is the distribution of weights; if
  a few samples carry most of the sample weight,
  heapification will pay for itself.  Since the case in BPF where a
  few samples carry most of the weight tends to be the case where the
  accuracy of the filter is low, this optimization may be of
  special benefit in a variable-population BPF technique
  such as KLD-sampling~\cite{kld}.

  For the normal case of resampling, we would like to get
  rid of the $\log m$ penalty per output sample.  However,
  there is a rarely-occuring special case in which this
  algorithm is especially efficient.  Consider an offline
  sampling problem in which we plan to repeatedly draw a
  small number of samples from the same extremely large
  input distribution.  Because the input distribution
  remains fixed, the cost of heapification can be amortized
  away, yielding an amortized $O(n \log m)$ algorithm.

\subsection{A Merge-based $O(m + n \log n)$ Resampling Algorithm}\label{sec-merge}

  One can imagine trying to improve upon the complexity of
  the heap-style algorithm by using some more efficient data
  structure.  However, there is a fundamental tradeoff---the
  setup for an improved algorithm needs to continue to have
  a cost low in $m$.  Otherwise, any savings in resampling
  will be swamped by setup in the common case that $m
  \approx n$.

  A better plan is to try to improve the na\"ive algorithm
  in a different way.  The real problem with the na\"ive
  algorithm is not so much the cost per scan of the input as it is the
  fact that each scan is independent.  It seems a shame not
  to try to do all the work in one scan.

  Let us generate an array $u$ of $n$ variates up-front,
  then sort it.  At this point, a {\em merge} operation, as
  shown in Figure~\ref{fig-merge}, can be used to generate
  all $n$ outputs in a single pass over the $m$ inputs.  The
  merge operation is simple.  Walk the input array once.
  Each time the sum of weights hits the current variate
  $u_i$, output a sample and move to the next variate
  $u_{i+1}$.  The time complexity of the initial sort is
  $O(n \log n)$ and of the merge pass is $O(m + n)$, for a
  total time complexity of $O(m + n \log n)$.

  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it merge}$(u)$: \\
      \>$j \asgn 1$ \\
      \>$t \asgn u_1$ \\
      \>{\bf for} $i$ {\bf from} $1$ {\bf to} $n$ {\bf do} \\
      \>\>$\mu \asgn u_i$ \\
      \>\>{\bf while} $\mu < t$ {\bf do} \\
      \>\>\>$t \asgn t + w(s_j)$ \\
      \>\>\>$j \asgn j + 1$ \\
      \>\>$s'_i \asgn s_j$
    \end{tabbing}
    \end{minipage}
    \caption{Merge-based Resampling}\label{fig-merge}
  \end{figure}

  Complexity-wise, we seem to have simply moved the $\log$
  factor of the previous algorithm from $m$ to $n$,
  replacing our $O(m + n \log m)$ algorithm with an $O(m + n
  \log n)$ one.  However, our new algorithm has an important
  distinction.  The log factor this time comes merely from
  sorting an array of uniform variates.  If we could somehow
  generate the variates in sorted order (at amortized
  constant cost) we could make this approach run in time
  $O(m + n)$.  The next section shows how to achieve this.

  Alternatively, if we could sort the variates in $O(n)$
  time, we could get an $O(m + n)$ merge-based algorithm.
  Given that what we are sorting is $n$ variates uniformly
  distributed between $0$ and $1$, a radix sort should do
  the trick here.  However, the constant factors in the running
  time are expected to be poor for large $n$, since the
  radix sort has extremely poor cache behavior.

\subsection{An Optimal $O(m + n)$ Resampling Algorithm}\label{sec-optimal}

  As discussed in the previous section, if we can generate
  the variates comprising a uniform sample of $n$ values in
  increasing order, we can resample in time $O(m + n)$.  In
  this section, we show an approach that achieves this
  goal.

  Assume without loss of generality that our goal is simply
  to generate the first variate in a uniform sample of $n +
  1$ values.  Call the first variate $\mu_0$, the set of
  remaining variates $U$ and note that $|U|=n$.  Now, for
  any given variate $\mu_i \in X$, we have that
    $$ \Prob(\mu_0 < \mu_i) = 1 - \mu_0 $$
  Since this is independently true for each $\mu_i$, we define
    $$p(\mu_0) = \Prob(\forall \mu_i \in U ~.~ \mu_0 < \mu_i) = (1 - \mu_0)^n$$
  
  To see how to take a weighted random sample from this
  distribution, first consider a discrete approximation that
  divides the range $0..1$ into $T$ intervals.  Given a
  random variate $\mu$, we will use $\mu_0=i_0/T$ when
  the sum of the weights of the intervals up to interval $i_0$
  is just greater than $\mu$.  Of course, the weights must be
  normalized by dividing by the total weight.  Thus we have
    $$i_0=\min_{i\in1..T}\left[{\frac{\sum_{j=1}^{i}{p(j/T)}}
                         {\sum_{j=1}^{T}{p(j/T)}} \ge \mu}\right]$$
  Figure~\ref{fig-calculus} illustrates the calculation
  here.  We output as our weighted variate the
  x-coordinate $i_0/T$ of the bar containing $\mu$.

  \begin{figure}
    \centering
    \includegraphics{bars}
    \caption{Discrete Sampling Approximation}\label{fig-calculus}
  \end{figure}

  In the limit as $T\rightarrow\infty$ our discrete
  approximation converges to an integral.  We have
    \begin{eqnarray*}
      \mu &=& \frac{\int_{u=0}^{\mu_0}{(1-u)^n \du}}
                   {\int_{u=0}^{1}{(1-u)^n \du}} \\
	  &=& \frac{\left.\frac{-(1-u)^{n+1}}{n+1}\right|_{u=0}^{\mu_0}}
		   {\left.\frac{-(1-u)^{n+1}}{n+1}\right|_{u=0}^{1}} \\
          &=& \frac{\frac{-1}{n+1}\left[(1-\mu_0)^{n+1}-1\right]}
		   {0-\frac{-1}{n+1}} \\
          &=& 1 - (1 - \mu_0)^{n+1}
    \end{eqnarray*}
  However, what we need is $\mu_0$ in terms of
  $\mu$, so we solve
    \begin{eqnarray*}
       \mu &=& 1 - (1 - \mu_0)^{n+1} \\
       (1 - \mu_0)^{n+1} &=& 1 - \mu \\
       \mu_0 &=& 1 - (1 - \mu)^\frac{1}{n+1} \\
       \mu_0 &=& 1 - \mu^\frac{1}{n+1}
    \end{eqnarray*}
  (The last step is permissible because $\mu$ is a
  uniform deviate in the range $0..1$, and therefore
  statistically equivalent to $(1-\mu)$.)

  We now have the formula we need for selecting the first
  deviate from a set of $n$ in increasing order.  To select
  the next deviate, we simply decrease $n$ by $1$, select a
  deviate from the whole range, and then scale and offset it
  to the remaining range.  We repeat this process until
  $n=0$.  (Recall that $|U|=n$, so the last deviate will be
  selected when $n=0$.)  Figure~\ref{fig-deviate} shows
  this process.
  
  \begin{figure}
    \centering
    \begin{minipage}{0.6\textwidth}
      \begin{tabbing}
      XX\=XXXX\=XXXX\=XXXX\=\kill
      {\bf to} {\it randomize}: \\
      \>$u_1 \asgn (1-\mu)^{\frac{1}{n}}$ \\
      \>{\bf for} $i$ {\bf from} $2$ {\bf to} $n$ {\bf do} \\
      \>\>$u_i \asgn u_{i-1} + (1-u_{i-1})(1-\mu)^{\frac{1}{n-i+1}}$
    \end{tabbing}
    \end{minipage}
    \caption{Generating Deviates In Increasing Order}\label{fig-deviate}
  \end{figure}

  We now have the array $u$ of deviates in sorted order that
  we need to feed the {\em merge} algorithm of the previous
  section.  We thus have an $O(m + n)$ algorithm for random
  weighted selection.

\subsection{Regular Approximate Resampling}\label{sec-regular}

  There are some obvious drawbacks to the optimal algorithm of
  the previous section.  Most notably, the version presented
  there requires one call to a floating-point power (general
  exponentiation) function for each output sample.  This can
  be quite expensive even on a fast machine; on a
  microcontroller it may not even be possible.

  For large $m$, a sorted array of uniform deviates looks an
  awful lot like it was produced by sampling at regular
  intervals; the spacing between deviates is pretty uniform.
  This suggests an obvious approximate linear-time
  algorithm, which turns out to be a well-known approach~\cite{kitagawa}:
  sample the $n$ output samples at uniformly-spaced regular
  intervals.  While it is not clear that such a resampling
  algorithm has the same statistical properties as a perfect
  resampling, it seems to be sufficiently good for our BPF
  implementation, and to run about as fast as possible.

  If one is concerned about the possible selection errors of
  regular sampling due to correlation, one might choose to
  shuffle the sample array prior to sampling.  Since the
  shuffle can be performed in $O(m)$ time, there is no
  asymptotic penalty.

\section{Performance}

  We implemented the algorithms described previously in a
  BPF tracker for simulated vehicle navigation.  The
  simulated vehicle has a GPS-like and an IMU-like device
  for navigational purposes; both the device and the vehicle
  model are noisy.  Figures~\ref{fig-track-naive} and
  \ref{fig-track-optimal} show 1000-step actual and estimated vehicle
  tracks from the simulator for the 100-particle case, using
  the na\"ive and optimal algorithms.  Note
  that the quality of tracking of the two algorithms is
  indistinguishable, as expected.

  \begin{figure}
    \centering
    \includegraphics{track-naive-100}
    \caption{Vehicle Tracking---BPF With Na\"ive Resampling}\label{fig-track-naive}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics{track-optimalsort-100}
    \caption{Vehicle Tracking---BPF With Optimal Resampling}\label{fig-track-optimal}
  \end{figure}

  The important distinction between the algorithms we have
  presented is not
  quality, but rather runtime.
  Figures~\ref{fig-times}-\ref{fig-timeszoom2} show the time
  in seconds for 1000 iterations of BPF with various
  resampling algorithms as a function of the number of
  particles tracked / resampled.  The benchmark machine is
  an otherwise unloaded Intel Core II Duo box at 2.13 GHz
  with 2GB of memory.

  \begin{figure}
    \centering
    \includegraphics{times}
    \caption{Runtimes for BPF Implementation}\label{fig-times}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics{timeszoom}
    \caption{Detail of Figure~\ref{fig-times}}\label{fig-timeszoom}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics{timeszoom2}
    \caption{Detail of Figure~\ref{fig-timeszoom}}\label{fig-timeszoom2}
  \end{figure}

  As expected, BPF using the na\"ive
  algorithm becomes unusable at larger particle sizes,
  whereas BPF using the optimal algorithm scales linearly.
  The heap-based algorithms are quite competitive with the
  optimal algorithm even at large particle counts, although
  the distinction is somewhat masked by the mediocre running
  time of the rest of the BPF implementation; resampling is
  not the bottleneck for any of these fast algorithms.  The
  performance of the regular algorithm illustrates
  this---the cost of that algorithm is quite close to zero,
  and thus represents something of a bound on the
  performance improvement possible through faster resampling.

  Sorting improves the performance of the na\"ive
  implementation substantially for larger $n$, although it
  does not pay until the particle count is around 500
  (Figure~\ref{fig-timeszoom}).  Heapification seems to
  always be worthwhile for the heap-based algorithm, though
  only significantly so for more than about 40,000
  particles.

  Our optimal algorithm is slightly out-performed by the
  heap-based algorithm until around 30,000 particles, and by
  the heap-based algorithm with heapification until around
  40,000 particles.  This, however, is reflective of the
  large constant factor we hope to eliminate in the optimal
  algorithm.  Once this is done, the performance of optimal
  and regular resampling should be very similar.

\section{Discussion}

  We have shown an $O(m + n)$ algorithm for perfect
  resampling, and an extremely fast BPF implementation based
  on this algorithm.  However, further speedups are
  possible.  In this section, we discuss some of them.

\subsection{Constant Factors}

  In a typical noise model, there is one call
  to a Gaussian-distributed pseudo-random number generator
  and to the {\tt exp()} function per particle {\em per
  sensor}: this is how the weights are updated.  These are the
  constant-factor bottlenecks in a BPF implementation with
  linear-time or near-linear-time resampling.

  The cost of generating Gaussian pseudo-random numbers can
  be reduced to insignificance by using Marsaglia and
  Tsang's ``Ziggurat Method'' PRNG~\cite{ziggurat}.  We
  observed an approximate doubling of speed in our BPF
  implementation by switching to this PRNG, and it is now
  far from being the bottleneck.

  The {\tt exp()} bottleneck is harder.  We have recently
  switched to a fast approximate exponentiation trick due to
  Schraudolph~\cite{exp}, which improved our performance
  considerably, but the large number of calls is still
  painful.  It may be better to just change noise
  distributions altogether.  Work is still underway in this
  area.


  The remaining bottleneck in resampling itself is the cost
  of the $O(n)$ calls to the {\tt pow()} function, each with
  a slightly different argument.  These rational
  exponentiations are computed during variate generation by
  calling the standard math library function {\tt pow(x,y)}.
  Since there is only one call to {\tt pow()} per particle,
  but many calls to {\tt exp()} per particle, this is not
  the bottleneck step for BPF.  However, it would be nice to
  cut it down, and approaches are available.

\subsubsection{Direct Generation of Variates}

  One way around the {\tt pow()} bottleneck is to generate
  random variates with distribution $(1 - x)^n$ by
  some less expensive method than that of
  Section~\ref{sec-optimal}.  The Ziggurat method mentioned
  previously would be about right, except that the desired
  distribution is a two-argument function.  The most direct
  approach would lead to generating $n$ sets of Ziggurat
  tables, which would be prohibitively memory-expensive for
  large $n$.

  
  When computing $(1 - x)^n$ for large $n$, however, our
  probability expression becomes self-similar, and we can
  accurately approximate the function for larger $n$ using
  the function with smaller $n$. $$
    (1 - x)^n \approx \left(1 - \frac{x}{a}\right)^{an}
  $$
  In fact, this is the well-known compound interest problem,
  yielding an elegant limiting approximation. $$
  \lim_{a \rightarrow \infty}\left(1 - \frac{x}{a}\right)^{an}
  =   \lim_{a \rightarrow \infty}\left(1 + \frac{(-x)}{a}\right)^{an}
  = e^{-xn}$$  This approximation corresponds to a standard 
  linear-time approximate resampling method in which the next sample
  weight is given by an exponentially-distributed
  variate~\cite{carpenter}.  The approximation works well up until near the
  end of the resampling, and is relatively inexpensive if a
  Ziggurat-style exponential generator is used.

  We can do better, though, by modifying the Ziggurat
  generator to accurately compute the desired power by
  tweaking the rejection step---this will converge poorly
  for the last 50 samples or so due to the degenerating
  approximation, at which point we can just switch to
  calling {\tt pow()} directly.

\subsubsection{Segmentation}\label{sec-segment}

  The concentration so far has been on generating the uniform
  variates sequentially.  However, for parallelization one
  would first like to break up the variates into blocks which
  are treated separately.  This is discussed further in
  Section~\ref{sec-parallel}.

  To break the variates up into blocks, we could try to
  derive a direct expression for placing sample $k$ of $n$
  for arbitrary $k$.  This would allow us to ``skip forward''
  by $k$ samples and place a variate, then deal with the
  intervening variates at our leisure.

  We observe that if a uniform variate $\mu_k$ is at
  position $k$ of $n$, $k - 1$ of the samples must have landed to the
  left of $\mu_k$ and $n - k$ of the samples must have
  landed to the right.  There are in general $\tbinom{n}{k-1}$
  ways this can happen, so the probability of $\mu_k$ being
  the $k^{\text{th}}$ sample is $$
    p(\mu_k) = \text{Pr}(\mu_k\text{ is at position }k) =
         \tbinom{n}{k - 1}(\mu_k)^{k-1}(1-\mu_k)^{n - k}
  $$
  The direct method used in Section~\ref{sec-optimal}
  next requires computing the probability that a variate
  $\mu$ is in the right position via $$
    p(\mu) = \text{Pr}(\mu_k = \mu) =
      \frac{\int_{u=0}^{\mu_k}{\tbinom{n}{k - 1}(\mu_k)^k(1-\mu_k)^{n - k}}\du}
           {\int_{u=0}^{1}{\tbinom{n}{k - 1}(\mu_k)^k(1-\mu_k)^{n - k}}\du}
  $$
  The integral in the denominator can be calculated
  directly. $$
    \int_{u=0}^{1}{\tbinom{n}{k - 1}(\mu_k)^k(1-\mu_k)^{n - k}}\du = 
        \tbinom{n}{k - 1}\frac{\Gamma(1 + n - k)\Gamma(k)}{\Gamma(n + 1)}
  $$
  Unfortunately, the integral in the numerator is more of a
  mess: $$
    \int_{u=0}^{\mu_k}{\tbinom{n}{k - 1}(\mu_k)^k(1-\mu_k)^{n - k}}\du =
        \tbinom{n}{k - 1}(\mu_k)^k\,\hyperg(k, -n + k; k + 1; \mu_k)
  $$
  where $\hyperg$ is Gauss's hypergeometric function.

  Any further progress in this direction appears to be
  limited by the difficulty of solving $p(\mu)$
  for $\mu_0$.  A rejection method for direction generation
  of $\mu_0$ would probably be a better approach here---a
  somewhat inefficient method would be fine, since few calls
  would be made to this generator.  Alternatively, one could
  just give up and divide the range uniformly.  The error of
  this approximation should be extremely small, and it would
  avoid a lot of complexity.
  
\subsection{Paralellization}\label{sec-parallel}

  Our optimal algorithm will parallelize reasonably well
  with some additional work. 
  \begin{enumerate}
  \item Each processor fills in a section of total
    accumulated weights in the input particle array as
    described in Section~\ref{sec-merge}.
  \item In a separate pass, each processor adds the sum of
    weights computed by the processor to its left to its
    section of the total accumulated weights in the input
    particle array.
  \item A master processor uses one of the methods of
    ``skipping ahead'' in the variate
    sequence described in the previous section to break up the
    array of variates to be calculated by our $P$-processor
    machine into $P$ regions.
  \item \label{enum-penultimate} Each processor does a search for the start and end
    of its section of the input particle array---the section
    whose total weights contain its variates.  This can be done in time
    $O(\log m)$ using binary search, with an impressively
    small constant factor.
  \item Finally, each processor resamples its section of the array
    using any of the fast algorithms we describe.  The key
    here is that these algorithms are all completely
    parallelizable with zero overhead, given the setup of
    steps~1--\ref{enum-penultimate}.
  \end{enumerate}

\subsection{Recommendations}

  There appear to be three basic regimes that weighted
  resampling is deployed in.  The choice among the algorithms
  presented here may be largely guided by the deployment.

  In the ``offline'' environment, extremely fast desktop
  computers or even supercomputers are being used in
  resampling.  In this regime, the cost of floating point is
  low, the desired resampling accuracy is high, millions or
  billions of input samples may be presented to the
  resampler, and parallel processing is often a real option.
  The perfect optimal algorithm seems like an ideal choice
  in this domain.  One example of this environment is BPF
  for biomedical signal procesing, with which we have had
  some involvement.

  In the ``high performance embedded'' environment, a single
  high-performance CPU, typically without floating point, is
  available, the desired resampling accuracy is high,
  real-time performance is usually required, and thousands
  to tens of thousands of input samples may be preseted to
  the resampler.  In this environment, either our optimal
  resampler or regular resampling with shuffle may be
  appropriate.  One example of this environment is the BPF
  sensor fusion on the PPC Linux flight computer aboard our
  amateur sounding rocket, for which this BPF implementation
  was originally developed.

  In the ``low-end embedded'' environment, a fairly slow
  CPU, typically without floating point, is available, the
  desired resampling accuracy is only moderate, real-time
  performance is usually required, and hundreds to tens of
  thousands of input samples may be presented to the
  resampler.  In this regime, a regular resampler, which
  can be implemented in a very small amount of very fast
  fixed-point or integer code, seems to be the best match.
  One example of this environment is a proprietary real-time
  BPF sensor fusion application for a portable ARM-7 device
  that we are currently working on.

\section*{Acknowledgments}

  Thanks much to Jules Kongslie, Mark Jones, Dave Archer,
  Jamey Sharp, Josh Triplett and Bryant York for
  illuminating conversations during the discussion of this
  work.  Thanks in particular to Josh for his suggestion on
  speeding up optimal sampling.  Thanks also to Jules
  Kongslie and to James McNames and his students for
  teaching me BPF.  It is my $n^{\text{th}}$ attempt to
  learn the topic, but this time it worked.

\section*{Availability}

  Our C implementation of BPF with linear resampling
  described here is freely available under the GPL at
  \url{http://wiki.cs.pdx.edu/bartforge/bmpf}.

\bibliographystyle{plain}
\bibliography{ltrs}

\end{document}
